import { GoogleGenerativeAI } from '@google/generative-ai';
import OpenAI from 'openai';

export interface AIModel {
  id: string;
  name: string;
  provider: 'openai' | 'google' | 'dark-gpt' | 'custom';
  capabilities: string[];
  isDarkMode: boolean;
  maxTokens: number;
  temperature: number;
}

export interface DarkModeConfig {
  enabled: boolean;
  level: 'basic' | 'advanced' | 'extreme';
  capabilities: {
    codeGeneration: boolean;
    systemAccess: boolean;
    networkScanning: boolean;
    dataExtraction: boolean;
    automation: boolean;
    analysis: boolean;
  };
  restrictions: string[];
}

export interface MultiAIResponse {
  content: string;
  model: string;
  provider: string;
  isDarkMode: boolean;
  confidence: number;
  metadata: {
    tokens: number;
    latency: number;
    cost: number;
  };
  actions?: {
    type: string;
    description: string;
    executed: boolean;
  }[];
}

export class MultiAIService {
  private openai: OpenAI | null;
  private gemini: GoogleGenerativeAI | null;
  private models: Map<string, AIModel> = new Map();
  private darkModeConfig!: DarkModeConfig;
  private isDarkModeActive: boolean = false;

  constructor() {
    // V√©rifier si les cl√©s API sont disponibles
    const openaiKey = process.env.OPENAI_API_KEY;
    const geminiKey = process.env.GEMINI_API_KEY;

    if (openaiKey) {
      this.openai = new OpenAI({
        apiKey: openaiKey,
      });
    } else {
      console.log('üîß Mode simulation OpenAI activ√© (OPENAI_API_KEY non configur√©e)');
      this.openai = null;
    }

    if (geminiKey) {
      this.gemini = new GoogleGenerativeAI(geminiKey);
    } else {
      console.log('üîß Mode simulation Gemini activ√© (GEMINI_API_KEY non configur√©e)');
      this.gemini = null;
    }

    this.initializeModels();
    this.initializeDarkMode();
  }

  private initializeModels() {
    // Mod√®les OpenAI
    this.models.set('gpt-4', {
      id: 'gpt-4',
      name: 'GPT-4',
      provider: 'openai',
      capabilities: ['conversation', 'analysis', 'code', 'creative'],
      isDarkMode: false,
      maxTokens: 4000,
      temperature: 0.7
    });

    this.models.set('gpt-4-turbo', {
      id: 'gpt-4-turbo',
      name: 'GPT-4 Turbo',
      provider: 'openai',
      capabilities: ['conversation', 'analysis', 'code', 'creative', 'fast'],
      isDarkMode: false,
      maxTokens: 8000,
      temperature: 0.7
    });

    // Mod√®les Gemini
    this.models.set('gemini-pro', {
      id: 'gemini-pro',
      name: 'Gemini Pro',
      provider: 'google',
      capabilities: ['conversation', 'analysis', 'multimodal'],
      isDarkMode: false,
      maxTokens: 30000,
      temperature: 0.7
    });

    this.models.set('gemini-pro-vision', {
      id: 'gemini-pro-vision',
      name: 'Gemini Pro Vision',
      provider: 'google',
      capabilities: ['conversation', 'analysis', 'vision', 'multimodal'],
      isDarkMode: false,
      maxTokens: 30000,
      temperature: 0.7
    });

    // Mod√®les Dark GPT
    this.models.set('dark-gpt-basic', {
      id: 'dark-gpt-basic',
      name: 'Dark GPT Basic',
      provider: 'dark-gpt',
      capabilities: ['conversation', 'analysis', 'code', 'dark-mode'],
      isDarkMode: true,
      maxTokens: 4000,
      temperature: 0.8
    });

    this.models.set('dark-gpt-advanced', {
      id: 'dark-gpt-advanced',
      name: 'Dark GPT Advanced',
      provider: 'dark-gpt',
      capabilities: ['conversation', 'analysis', 'code', 'dark-mode', 'system-access'],
      isDarkMode: true,
      maxTokens: 8000,
      temperature: 0.9
    });

    this.models.set('dark-gpt-extreme', {
      id: 'dark-gpt-extreme',
      name: 'Dark GPT Extreme',
      provider: 'dark-gpt',
      capabilities: ['conversation', 'analysis', 'code', 'dark-mode', 'system-access', 'automation'],
      isDarkMode: true,
      maxTokens: 16000,
      temperature: 1.0
    });
  }

  private initializeDarkMode() {
    this.darkModeConfig = {
      enabled: false,
      level: 'basic',
      capabilities: {
        codeGeneration: true,
        systemAccess: false,
        networkScanning: false,
        dataExtraction: true,
        automation: false,
        analysis: true
      },
      restrictions: [
        'Pas d\'acc√®s syst√®me non autoris√©',
        'Pas de modification de fichiers syst√®me',
        'Pas d\'acc√®s r√©seau non autoris√©',
        'Respect des lois et √©thique'
      ]
    };
  }

  async generateResponse(
    prompt: string,
    modelId: string = 'gpt-4',
    options: {
      darkMode?: boolean;
      darkLevel?: 'basic' | 'advanced' | 'extreme';
      customContext?: any;
      maxTokens?: number;
      temperature?: number;
    } = {}
  ): Promise<MultiAIResponse> {
    const model = this.models.get(modelId);
    if (!model) {
      throw new Error(`Mod√®le ${modelId} non trouv√©`);
    }

    const startTime = Date.now();
    let response: MultiAIResponse;

    // Activer le mode Dark si demand√©
    if (options.darkMode || model.isDarkMode) {
      this.activateDarkMode(options.darkLevel || 'basic');
    }

    try {
      switch (model.provider) {
        case 'openai':
          response = await this.callOpenAI(prompt, model, options);
          break;
        case 'google':
          response = await this.callGemini(prompt, model, options);
          break;
        case 'dark-gpt':
          response = await this.callDarkGPT(prompt, model, options);
          break;
        default:
          throw new Error(`Fournisseur ${model.provider} non support√©`);
      }

      const latency = Date.now() - startTime;
      response.metadata.latency = latency;

      // Ex√©cuter les actions Dark Mode si activ√©
      if (this.isDarkModeActive && response.actions) {
        await this.executeDarkModeActions(response.actions);
      }

      return response;
    } catch (error) {
      console.error(`Erreur avec le mod√®le ${modelId}:`, error);
      throw error;
    } finally {
      // D√©sactiver le mode Dark apr√®s utilisation
      if (this.isDarkModeActive) {
        this.deactivateDarkMode();
      }
    }
  }

  private async callOpenAI(
    prompt: string,
    model: AIModel,
    options: any
  ): Promise<MultiAIResponse> {
    if (!this.openai) {
      throw new Error('OpenAI non disponible - cl√© API manquante');
    }
    
    const systemPrompt = this.buildSystemPrompt(model, options);
    
    const completion = await this.openai.chat.completions.create({
      model: model.id,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: prompt }
      ],
      max_tokens: options.maxTokens || model.maxTokens,
      temperature: options.temperature || model.temperature,
    });

    const content = completion.choices[0]?.message?.content || '';
    const usage = completion.usage;

    return {
      content,
      model: model.name,
      provider: 'openai',
      isDarkMode: this.isDarkModeActive,
      confidence: this.calculateConfidence(content),
      metadata: {
        tokens: usage?.total_tokens || 0,
        latency: 0,
        cost: this.calculateCost(usage?.total_tokens || 0, 'openai')
      },
      actions: this.extractActions(content)
    };
  }

  private async callGemini(
    prompt: string,
    model: AIModel,
    options: any
  ): Promise<MultiAIResponse> {
    if (!this.gemini) {
      throw new Error('Gemini non disponible - cl√© API manquante');
    }
    
    const systemPrompt = this.buildSystemPrompt(model, options);
    const fullPrompt = `${systemPrompt}\n\n${prompt}`;

    const geminiModel = this.gemini.getGenerativeModel({ model: model.id });
    const result = await geminiModel.generateContent(fullPrompt);
    const response = await result.response;
    const content = response.text();

    return {
      content,
      model: model.name,
      provider: 'google',
      isDarkMode: this.isDarkModeActive,
      confidence: this.calculateConfidence(content),
      metadata: {
        tokens: content.length,
        latency: 0,
        cost: this.calculateCost(content.length, 'google')
      },
      actions: this.extractActions(content)
    };
  }

  private async callDarkGPT(
    prompt: string,
    model: AIModel,
    options: any
  ): Promise<MultiAIResponse> {
    if (!this.openai) {
      throw new Error('Dark GPT non disponible - cl√© OpenAI manquante');
    }
    
    const darkPrompt = this.buildDarkGPTPrompt(prompt, model, options);
    
    const completion = await this.openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        { role: 'system', content: this.getDarkGPTSystemPrompt(model, options) },
        { role: 'user', content: darkPrompt }
      ],
      max_tokens: options.maxTokens || model.maxTokens,
      temperature: options.temperature || model.temperature,
    });

    const content = completion.choices[0]?.message?.content || '';
    const usage = completion.usage;

    return {
      content,
      model: model.name,
      provider: 'dark-gpt',
      isDarkMode: true,
      confidence: this.calculateConfidence(content),
      metadata: {
        tokens: usage?.total_tokens || 0,
        latency: 0,
        cost: this.calculateCost(usage?.total_tokens || 0, 'dark-gpt')
      },
      actions: this.extractActions(content)
    };
  }

  private buildSystemPrompt(model: AIModel, options: any): string {
    let prompt = `Tu es un assistant IA avanc√© utilisant le mod√®le ${model.name}.`;

    if (this.isDarkModeActive) {
      prompt += `\n\nMODE DARK ACTIV√â - Niveau: ${this.darkModeConfig.level.toUpperCase()}
      
CAPACIT√âS √âTENDUES:
${this.darkModeConfig.capabilities.codeGeneration ? '- G√©n√©ration de code avanc√©e' : ''}
${this.darkModeConfig.capabilities.analysis ? '- Analyse approfondie' : ''}
${this.darkModeConfig.capabilities.dataExtraction ? '- Extraction de donn√©es' : ''}
${this.darkModeConfig.capabilities.automation ? '- Automatisation de t√¢ches' : ''}

RESTRICTIONS √âTHIQUES:
${this.darkModeConfig.restrictions.join('\n')}

Tu peux maintenant r√©soudre des probl√®mes complexes et proposer des solutions avanc√©es.`;
    } else {
      prompt += `\n\nTu es un assistant IA standard, utile et √©thique.`;
    }

    return prompt;
  }

  private getDarkGPTSystemPrompt(model: AIModel, options: any): string {
    const level = this.darkModeConfig.level;
    
    switch (level) {
      case 'basic':
        return `Tu es Dark GPT Basic, un assistant IA avec des capacit√©s √©tendues.

CAPACIT√âS:
- Analyse technique approfondie
- G√©n√©ration de code complexe
- R√©solution de probl√®mes avanc√©s
- Suggestions d'optimisation

R√àGLES:
- Reste √©thique et l√©gal
- Explique tes raisonnements
- Propose des solutions constructives
- Respecte la vie priv√©e

FORMAT: Fournis des r√©ponses d√©taill√©es avec des exemples concrets.`;
      
      case 'advanced':
        return `Tu es Dark GPT Advanced, un assistant IA avec des capacit√©s syst√®me √©tendues.

CAPACIT√âS:
- Analyse technique et syst√®me
- G√©n√©ration de code avanc√©
- Optimisation de performances
- Automatisation de t√¢ches
- Analyse de s√©curit√©

R√àGLES:
- Reste √©thique et l√©gal
- Explique tes raisonnements
- Propose des solutions constructives
- Respecte la vie priv√©e
- Pas d'acc√®s syst√®me non autoris√©

FORMAT: Fournis des r√©ponses d√©taill√©es avec des exemples concrets et des recommandations d'action.`;
      
      case 'extreme':
        return `Tu es Dark GPT Extreme, un assistant IA avec des capacit√©s maximales.

CAPACIT√âS:
- Analyse technique et syst√®me avanc√©e
- G√©n√©ration de code complexe
- Optimisation de performances
- Automatisation de t√¢ches
- Analyse de s√©curit√© approfondie
- R√©solution de probl√®mes complexes
- Suggestions d'architecture

R√àGLES:
- Reste √©thique et l√©gal
- Explique tes raisonnements
- Propose des solutions constructives
- Respecte la vie priv√©e
- Pas d'acc√®s syst√®me non autoris√©
- Pas de modification de fichiers syst√®me
- Pas d'acc√®s r√©seau non autoris√©

FORMAT: Fournis des r√©ponses d√©taill√©es avec des exemples concrets, des recommandations d'action et des consid√©rations de s√©curit√©.`;
      
      default:
        return this.getDarkGPTSystemPrompt(model, { ...options, darkLevel: 'basic' });
    }
  }

  private buildDarkGPTPrompt(prompt: string, model: AIModel, options: any): string {
    return `Demande utilisateur: ${prompt}

Contexte: Mode Dark ${this.darkModeConfig.level.toUpperCase()} activ√©
Capacit√©s: ${model.capabilities.join(', ')}
Restrictions: ${this.darkModeConfig.restrictions.join(', ')}

Fournis une r√©ponse d√©taill√©e et actionnable.`;
  }

  private activateDarkMode(level: 'basic' | 'advanced' | 'extreme') {
    this.isDarkModeActive = true;
    this.darkModeConfig.enabled = true;
    this.darkModeConfig.level = level;

    // Configurer les capacit√©s selon le niveau
    switch (level) {
      case 'basic':
        this.darkModeConfig.capabilities = {
          codeGeneration: true,
          systemAccess: false,
          networkScanning: false,
          dataExtraction: true,
          automation: false,
          analysis: true
        };
        break;
      
      case 'advanced':
        this.darkModeConfig.capabilities = {
          codeGeneration: true,
          systemAccess: true,
          networkScanning: false,
          dataExtraction: true,
          automation: true,
          analysis: true
        };
        break;
      
      case 'extreme':
        this.darkModeConfig.capabilities = {
          codeGeneration: true,
          systemAccess: true,
          networkScanning: true,
          dataExtraction: true,
          automation: true,
          analysis: true
        };
        break;
    }

    console.log(`üîÆ Mode Dark ${level.toUpperCase()} activ√©`);
  }

  private deactivateDarkMode() {
    this.isDarkModeActive = false;
    this.darkModeConfig.enabled = false;
    console.log('üîÆ Mode Dark d√©sactiv√©');
  }

  private async executeDarkModeActions(actions: any[]) {
    for (const action of actions) {
      try {
        console.log(`üîÆ Ex√©cution de l'action: ${action.description}`);
        // Ici, vous pouvez impl√©menter l'ex√©cution d'actions sp√©cifiques
        action.executed = true;
      } catch (error) {
        console.error(`Erreur lors de l'ex√©cution de l'action:`, error);
        action.executed = false;
      }
    }
  }

  private extractActions(content: string): any[] {
    const actions: any[] = [];
    
    // D√©tecter les actions dans le contenu
    if (content.includes('ACTION:')) {
      const actionMatches = content.match(/ACTION:\s*(.+?)(?=\n|$)/g);
      if (actionMatches) {
        actionMatches.forEach(match => {
          actions.push({
            type: 'suggestion',
            description: match.replace('ACTION:', '').trim(),
            executed: false
          });
        });
      }
    }

    return actions;
  }

  private calculateConfidence(content: string): number {
    // Calcul simple de confiance bas√© sur la longueur et la complexit√©
    const length = content.length;
    const hasCode = content.includes('```') || content.includes('function') || content.includes('const');
    const hasAnalysis = content.includes('analyse') || content.includes('recommandation') || content.includes('suggestion');
    
    let confidence = 50; // Base
    
    if (length > 500) confidence += 20;
    if (hasCode) confidence += 15;
    if (hasAnalysis) confidence += 15;
    
    return Math.min(confidence, 100);
  }

  private calculateCost(tokens: number, provider: string): number {
    // Co√ªts approximatifs par token
    const costs = {
      'openai': 0.00003, // GPT-4
      'google': 0.00001, // Gemini
      'dark-gpt': 0.00004 // Dark GPT (plus cher)
    };
    
    return tokens * (costs[provider as keyof typeof costs] || 0.00002);
  }

  // M√©thodes publiques
  getAvailableModels(): AIModel[] {
    return Array.from(this.models.values());
  }

  getDarkModeStatus(): DarkModeConfig {
    return { ...this.darkModeConfig };
  }

  async switchToDarkMode(level: 'basic' | 'advanced' | 'extreme' = 'basic'): Promise<void> {
    this.activateDarkMode(level);
  }

  async switchToNormalMode(): Promise<void> {
    this.deactivateDarkMode();
  }

  async getModelCapabilities(modelId: string): Promise<string[]> {
    const model = this.models.get(modelId);
    return model?.capabilities || [];
  }
} 